# -*- after-save-hook: org-html-export-to-html; org-export-in-background: t; -*-
#+TITLE:Solutions to Homework 1
#+AUTHOR:Darlan Cavalcante Moreira
#+EMAIL:darcamo@gmail.com
#+SETUPFILE: ~/.emacs.d/lisp/org-setup-file-template/setup.org

#+LATEX_HEADER: \renewcommand{\theenumi}{\Alph{enumi}}
#+HTML_HEAD: <style>ol {list-style-type: lower-latin;}</style>

#+HTML: \(\require{cancel}\)


* Exercise 1
  
  \begin{align*}
  f(z) = f(x+jy) = u(x,y) + j v(x,y) \\
  \frac{df}{dz} = \lim_{\Delta z \rightarrow 0} \frac{f(z+\Delta z) - f(z) }{\Delta z}
  \end{align*}
  
  a. $\Delta z = \Delta x$

     \begin{align*}
     \frac{df}{dz} & = \lim_{\Delta x \rightarrow 0} = \frac{u (x+\Delta x, y) - u(x,y) + jv(x+\Delta x, y) - jv(x,y)}{\Delta x}\\
                   & = \frac{\partial u}{\partial x} + j \frac{\partial v}{\partial x}
     \end{align*}
     
  b. $\Delta z = j \Delta y$

     \begin{align*}
     \frac{df}{dz} & = \lim_{\Delta y \rightarrow 0} = \frac{u (x, y + j\Delta y) - u(x,y) + jv(x, y + j\Delta y) - jv(x,y)}{j \Delta y}\\
     \end{align*}

     Now let's multiply the numerator and denominator by $j$.

     \begin{align*}
     \frac{df}{dz} & = \frac{j(u (x, y + \Delta y) - u(x,y)) - (v(x, y + \Delta y) - jv(x,y))}{-\Delta y}\\
                   & = -j\frac{\partial u}{\partial y} + \frac{\partial v}{\partial y}
     \end{align*}

  c. With both results we now have

     \[\frac{\partial u}{\partial x} + j \frac{\partial v}{\partial x} = -j\frac{\partial u}{\partial y} + \frac{\partial v}{\partial y}\]
     
     For this to hold the real part in both sides must be equal, as well as the
     imaginary part in both sides. Therefore, we have that

     \[\frac{\partial u}{\partial x} = \frac{\partial v}{\partial y} \qquad \text{and} \qquad \frac{\partial v}{\partial x} = -\frac{\partial u}{\partial y}\]

  d. These two equations are exactly the Cauchy-Riemann equations.
                   
* Exercise 2
* Exercise 3
  a. In order to answer this we need to show that $\vtW \mtR \vtW$ is real
     valued. Since $\mtR = \mtR^H$ we have that $\mtR = \mtQ \Lambda \mtQ^H$,
     with $\Lambda$ being a diagonal matrix with the eigenvalues. Then
  
     \[\underbrace{\vtW \mtQ}_{\vtV^H} \Lambda \underbrace{\mtQ^H \vtW}_{\vtV} = \vtV^H \Lambda \vtV\]

     Since $\Lambda$ is a diagonal matrix this is equivalent to the weighted
     norm of $\vtV$ where the weights are the diagonal elements in
     $\Lambda$. That is,

     \[\vtV^H \Lambda \vtV\ = \sum_i v_i^* \Lambda^{[i]}v_i = \sum_i \Lambda^{[i]} \vert v_i \vert^2 \in \bbR\]
  
     where $\Lambda^{[i]}$ is the $i$th diagonal element of $\Lambda$.

  b. \[I(\vtW, \vtW^*) = (\vtW^*)^T \mtR \vtW - (\vtW^*)^T \vtP - \vtW^T \vtP^*\]
     \[\frac{\partial I}{\partial \vtW^*} = \mtR \vtW - \vtP = 0 \Rightarrow \boxed{\vtW = \mtR^{-1} \vtP}\]

  c. First let's take the transpose of the quadratic term. This does not change the equation, since each term is a scalar value. We have that

     \begin{align*}
     I(\vtW, \vtW^*) & = \vtW^T \mtR^T \vtW^* - (\vtW^*)^T \vtP - \vtW^T \vtP^* \\
     \frac{\partial I}{\partial \vtW} & = \mtR^T \vtW^* - \vtP^* = 0 \\
     & = \vtW^* = (\mtR^T)^{-1}\vtP^* \\
     & = \boxed{\vtW = (\mtR^H)^{-1}\vtP}
     \end{align*}

  d. The answers are different, unless $\mtR$ is an Hermitian matrix (which
     always occur when it is a covariance matrix). In that case both
     derivatives yield the same answer.
* Exercise 4

  a. Solving (9) for $x_2$ we get
     
     \begin{align*}
     2x_2 = 1+x_1 \\
     \boxed{x_2 = \frac{1+x_1}{2}}
     \end{align*}

     Replacing in (8) we get

     \begin{align*}
     f(x_1) & = 1 + \cancel{2} x_1 \left(\frac{1+x_1}{\cancel{2}}\right) + x_1^2 + 3 \left(\frac{1+x_1}{2}\right)^2 \\
     & = 1 + x_1 + x_1^2 + x_1^2 + \frac{3}{4}(1 + 2 x_1 + x_1^2) \\
     & = 1 + x_1 + 2x_1^2 + \frac{3}{4} + \frac{6}{4} x_1 + \frac{3}{4} x_1^2 \\
     & = \frac{4 + 4 x_1 + 8 x_1^2 + 3 + 6 x_1 + 3 x_1^2}{4} \\
     f(x_1) & = 7 + 10 x_1 + 11 x_1^2
     \end{align*}
     
     Taking the derivative of $f$ we get
     
     \begin{align*}
     \frac{d f}{d x_1} & = 10 + 22 x_1 = 0 \Rightarrow x_1 = -\frac{10}{22} \\
     & \boxed{x_1  = -\frac{5}{11}} \\
     & \boxed{x_2 = \frac{3}{11}}
     \end{align*}

  b. The Lagrangian is given by
     
     \[L(x_1,x_2,\lambda) = 1 + 2 x_1 x_2 + x_1^2 + 3 x_2^2 + \lambda (1 + x_1 - 2 x_2)\]

     Now we take the partial derivatives as below

     \begin{align*}
     \frac{\partial L}{\partial x_1} & = 2 x_2 + 2 x_1 + \lambda = 0 \Rightarrow \lambda = -2 x_2 -2 x_1 \\
     \frac{\partial L}{\partial x_2} & = 2 x_1 + 6 x_2 - 2 \lambda = 0 \Rightarrow 3 x_1 + 5 x_2 = 0 \\
     \frac{\partial L}{\partial \lambda} & = 1 + x_1 - 2 x_2 = 0 \Rightarrow x_1 = 2 x_2 - 1
     \end{align*}

     Replacing the third equation in the second we get

     \begin{align*}
     3(2 x_2 - 1) + 5 x_2 = 0 \\
     6 x_2 -3 + 5x2 = 0 \\
     11 x_2 = 3 \Rightarrow \boxed{x_2 = \frac{3}{11}}
     \end{align*}

     Now we calculate the value of \(x_1\) as
     
     \begin{align*}
     x_1 = \frac{2 \cdot 3}{11} - 1 = \frac{6}{11} \\
     \boxed{x_1 = -\frac{5}{11}}
     \end{align*}
  

* Exercise 5

  This is a quadratic problem with linear constraints in the form

  \begin{equation}
    \begin{cases}
      \displaystyle \min_\vtW & f(\vtW) = \vtW^H \mtR \vtW \\
      \text{s.t.} & \mtS^H \vtW - \vtG = 0
    \end{cases}
  \end{equation}
  with 
  \[\mtR = \begin{bmatrix}1 & 0 & 0\\0 & 2 & 0\\0 & 0 & 3\end{bmatrix}, \quad \mtS = \begin{bmatrix}1 & -j\\j & 2\\1 & j\end{bmatrix} \quad \text{and} \quad \vtG = \begin{bmatrix}-1 \\ -1\end{bmatrix}.\]
  
  Calculating the Lagrangian we get
  
  \[L(\vtW, \vtLambda) = (\vtW^*)^T \mtR \vtW + (\vtLambda^*)^T(\mtS^H \vtW - \vtG) + \vtLambda^T(\mtS^T \vtW^* - \vtG^*)\]

  Now we can take the partial derivatives to get

  \begin{align*}
  \frac{\partial L}{\partial \vtW^*} & = \mtR \vtW + \mtS \vtLambda = 0 \Rightarrow \boxed{\vtW = - \mtR^{-1}\mtS \vtLambda} \\
  \frac{\partial L}{\partial \vtLambda^*} & = \mtS^H \vtW - \vtG = 0
  \end{align*}

  Replacing \(\vtW\) in the second equation we get

  \begin{align*}
  - \mtS^H \mtR^{-1}\mtS \vtLambda & = \vtG \\
  \mtS^H\mtR^{-1}\mtS \vtLambda & = -\vtG
  \end{align*}

  \[\therefore \boxed{\vtLambda = -(\mtS^H\mtR^{-1}\mtS)^{-1} \vtG}\]

  Now we can replace this back into equation of $\vtW$ to get 

  \[\vtW = \mtR^{-1}\mtS (\mtS^H\mtR^{-1}\mtS)^{-1} \vtG\]

  The inverse of $\mtR$ is trivial to compute and is given by
  
  \[\begin{bmatrix}1 & 0 & 0\\0 & \frac{1}{2} & 0\\0 & 0 & \frac{1}{3}\end{bmatrix}\]

  Now let's compute the value of \(\mtR^{-1}\mtS\)

  \[\mtR^{-1}\mtS = \begin{bmatrix}1 & - j\\ \frac{j}{2} & 1\\ \frac{1}{3} & \frac{j}{3}\end{bmatrix}\]

  and
  
  \[\mtS^H\mtR^{-1}\mtS = \begin{bmatrix}1 & - j & 1\\j & 2 & - j\end{bmatrix} \begin{bmatrix}1 & - j\\ \frac{j}{2} & 1\\ \frac{1}{3} & \frac{j}{3}\end{bmatrix} = \begin{bmatrix}1 + \frac{1}{2} + \frac{1}{3} & -1-j+\frac{j}{3} \\ j+j-\frac{j}{3} & 1+2+\frac{1}{3}\end{bmatrix} = \begin{bmatrix}\frac{11}{3} & -\frac{5j}{3} \\ \frac{5j}{3} & \frac{10}{3}\end{bmatrix}\]
  
  \[(\mtS^H\mtR^{-1}\mtS)^{-1} = \begin{bmatrix}1 & \frac{j}{2}\\ - \frac{j}{2} & \frac{11}{20}\end{bmatrix}\]

  Finally, we have that

  \begin{align*}
  \vtW = \begin{bmatrix}1 & - j\\ \frac{j}{2} & 1\\ \frac{1}{3} & \frac{j}{3}\end{bmatrix} \begin{bmatrix}1 & \frac{j}{2}\\ - \frac{j}{2} & \frac{11}{20}\end{bmatrix} \begin{bmatrix}-1 \\ -1\end{bmatrix} \\
  \vtW = \begin{bmatrix}-\frac{1}{2} + \frac{j}{20} \\-\frac{3}{10}\\-\frac{1}{2} - \frac{7j}{20} \end{bmatrix}
  \vtW = \frac{1}{20}\begin{bmatrix}-10+j \\ -6 \\ -10 -7j\end{bmatrix}
  \end{align*}
  
  


  
  # Therefore, lambda can be calculated as 
  
  # \[\vtLambda = \left[\begin{matrix}-2.0 - 1.0 i\\-1.1 + 1.0 i\end{matrix}\right]\]
